{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ee05b62-fb95-4912-9622-0b125aa8f304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "005a8a0d-89c8-47ef-864f-9e228beee491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_word_to_vec = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35654e6c-7654-474f-84c0-ee39330312a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2tag={0: 'O',\n",
    "         1: 'B-LOC',\n",
    "         2: 'B-GRP',\n",
    "         3: 'I-GRP',\n",
    "         4: 'B-PROD',\n",
    "         5: 'B-CW',\n",
    "         6: 'I-CW',\n",
    "         7: 'B-CORP',\n",
    "         8: 'B-PER',\n",
    "         9: 'I-PER',\n",
    "         10: 'I-CORP',\n",
    "         11: 'I-PROD',\n",
    "         12: 'I-LOC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "987fecf3-e432-4eaf-a0bd-0ed6efa59b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag2idx={'O': 0,\n",
    "         'B-LOC': 1,\n",
    "         'B-GRP': 2,\n",
    "         'I-GRP': 3,\n",
    "         'B-PROD': 4,\n",
    "         'B-CW': 5,\n",
    "         'I-CW': 6,\n",
    "         'B-CORP': 7,\n",
    "         'B-PER': 8,\n",
    "         'I-PER': 9,\n",
    "         'I-CORP': 10,\n",
    "         'I-PROD': 11,\n",
    "         'I-LOC': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3557235b-2f3f-4157-8fa6-4c0b21cbca22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "punctuations = '''“”!()-[]{};:'\"\\,<>./?@#$%^&*_~�।’‘1234567890''' #we can add suitable extra punctuation all the time\n",
    "def remove_punctuation(d):\n",
    "    review = d.replace('\\n', '')\n",
    "    no_punct = \"\"\n",
    "    for char in review:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bede89e8-c319-4fc9-a9fe-9a52f98205a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def input_file(fileName):\n",
    "    word = [[]]\n",
    "    sentences = [[]]\n",
    "    target = [[]]\n",
    "    count_class = {}\n",
    "    i=0\n",
    "    with open(fileName, 'r') as file:\n",
    "        for line in file:\n",
    "            l = line.split()\n",
    "            if len(l):\n",
    "                if l[0] not in punctuations:\n",
    "                    l[0] = remove_punctuation(l[0])\n",
    "                    word[i].append((l[0], l[-1]))\n",
    "                    target[i].append(l[-1])\n",
    "                    sentences[i].append(l[0])\n",
    "                    if l[-1] not in count_class.keys():\n",
    "                        count_class.update({l[-1]:1})\n",
    "                    else:\n",
    "                        count_class[l[-1]] += 1\n",
    "                else:\n",
    "                    word[i].append((l[0], l[-1]))\n",
    "                    sentences[i].append(l[0])\n",
    "            else:\n",
    "                word.append([])\n",
    "                sentences.append([])\n",
    "                target.append([])\n",
    "                i+=1\n",
    "    \n",
    "    return word, sentences, target, count_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e5bac6e-d678-4923-9254-a8f1c83da7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_token, train_sentence, train_target, count_class_train = input_file('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0127b329-9a87-401a-ba64-a6503e2c5371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_token, dev_sentence, dev_target, count_class_dev = input_file('dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f212bca-204a-45e3-b0f0-0421dd115662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mxlen = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7441f060-ba78-4cb2-a7a2-24df7cb03d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentence.append(['unknown'])\n",
    "train_target.append(['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39d4779e-e90a-4e96-913b-ca98bd2f7fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29176"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = train_sentence + dev_sentence\n",
    "flat_list = [item for sublist in vocab for item in sublist]\n",
    "unique_words = list(set(x for x in flat_list))\n",
    "len_unique_words = len(unique_words)\n",
    "len_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18d2b73b-c477-46c0-91df-e2ae0307f68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "x = [[model_word_to_vec.wv.get_vector(x) for x in s] for s in train_sentence]\n",
    "x = pad_sequences(maxlen = mxlen+5, sequences=x, padding='post', value=len_unique_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "650d0129-a655-4293-9d4d-8a175a238860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(count_class_train.keys())\n",
    "num_classes = len(labels)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1cad10d-17c2-4316-ab8a-2675f1bf1b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w] for w in s] for s in train_target]\n",
    "y = pad_sequences(maxlen = mxlen+5, sequences=y, padding='post', value=tag2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=num_classes) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc195ce1-17b0-46ac-87ba-2fa4f49c6a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15301, 55, 100)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd1053ea-b33f-4507-9e14-e64133e6d72d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15301"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a48f5014-5cab-470e-b471-f4b16250a3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_input = [elem for twod in x for elem in twod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e491e6d3-6217-4c1d-b617-bc0d79fddac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841555"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b9f62fc-a9df-46f1-b0cb-e2fcb96c7e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_input = [elem for twod in y for elem in twod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "207a75f5-805a-4293-be1a-074f6c9ddc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841555"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a18c49e8-c5d1-4e6f-86e2-6ad7fd473bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02528ba4-929a-421d-ace7-44935045cfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_input, y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e99d12d-37f4-4d8e-a891-41d2a722813f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "x = [[model_word_to_vec.wv.get_vector(x) for x in s] for s in dev_sentence]\n",
    "x = pad_sequences(maxlen = mxlen+5, sequences=x, padding='post', value=len_unique_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fac872ba-220e-47c5-90b9-0d66e1f815a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [elem for twod in x for elem in twod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af499ee7-9b96-4f3d-a72d-32559eb54123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "165d8d1f-94f5-4847-8ba7-5fbb91947736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44000, 13)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd7881e1-54f0-42de-b088-9959a7012b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initializing K \n",
    "K = 55\n",
    "  \n",
    "# Convert 2D list to 3D at K slicing\n",
    "# Using loop\n",
    "res = []\n",
    "subl = []\n",
    "cnt = 0\n",
    "for sub in y_pred:\n",
    "    subl.append(sub)\n",
    "    cnt = cnt + 1\n",
    "    if cnt >= K:\n",
    "        res.append(subl)\n",
    "        subl = []\n",
    "        cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6adaf842-c918-465e-b7d1-3738290976f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aaac43c6-e36d-4961-ac1e-087c6962737c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l = [[]]\n",
    "for i, sent in enumerate(dev_sentence):\n",
    "    for j, word in enumerate(sent):\n",
    "        l[i].append(np.argmax(res[i][j]))\n",
    "    if i<len(dev_sentence)-1:\n",
    "        l.append([])\n",
    "        \n",
    "dev_labels = [[]]\n",
    "for i, sent in enumerate(dev_sentence):\n",
    "    for j, word in enumerate(sent):\n",
    "        dev_labels[i].append(idx2tag[l[i][j]])\n",
    "    if i<len(dev_sentence)-1:\n",
    "        dev_labels.append([])\n",
    "\n",
    "with open('dev_pred_f.txt', 'w') as f:\n",
    "    for line in dev_labels:\n",
    "        for word in line:\n",
    "            f.write(f\"{word}\\n\")\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34117edb-ad6d-4715-9bab-0eca3273ea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "punctuations = '''“”!()-[]{};:'\"\\,<>./?@#$%^&*_~�।’‘1234567890''' #we can add suitable extra punctuation all the time\n",
    "def remove_punctuation(d):\n",
    "    review = d.replace('\\n', '')\n",
    "    no_punct = \"\"\n",
    "    for char in review:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "905031d7-4113-4327-ae39-187537250ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_file_test(fileName):\n",
    "    word = [[]]\n",
    "    sentences = [[]]\n",
    "    target = [[]]\n",
    "    count_class = {}\n",
    "    i=0\n",
    "    with open(fileName, 'r') as file:\n",
    "        for line in file:\n",
    "            l = line.split()\n",
    "            if len(l):\n",
    "                if l[0] not in punctuations:\n",
    "                    l[0] = remove_punctuation(l[0])\n",
    "                    if l[0] not in unique_words:\n",
    "                        word[i].append('unknown')\n",
    "                    else:\n",
    "                        word[i].append(l[0])\n",
    "                else:\n",
    "                    if l[0] not in unique_words:\n",
    "                        word[i].append('unknown')\n",
    "                    else:\n",
    "                        word[i].append(l[0])\n",
    "            else:\n",
    "                word.append([])\n",
    "                i+=1\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9859d93d-3edf-450f-8f0d-8899ab7c7af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_word = input_file_test('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1dd2ac48-cea7-4b92-b7cb-08ac1dd8dc15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test = [[model_word_to_vec.wv.get_vector(x) for x in s] for s in test_word]\n",
    "x_test = pad_sequences(maxlen = mxlen+5, sequences=x_test, padding='post', value=len_unique_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e310bbba-681d-4cd2-bf2a-dd9a6bda6b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_input_test = [elem for twod in x_test for elem in twod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3fcc4ff6-a224-4979-bf66-5efa0c172a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = rf.predict(x_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99ffeb7f-913e-41af-89dd-d4f4933d0971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initializing K \n",
    "K = 55\n",
    "  \n",
    "# Convert 2D list to 3D at K slicing\n",
    "# Using loop\n",
    "res = []\n",
    "subl = []\n",
    "cnt = 0\n",
    "for sub in y_test_pred:\n",
    "    subl.append(sub)\n",
    "    cnt = cnt + 1\n",
    "    if cnt >= K:\n",
    "        res.append(subl)\n",
    "        subl = []\n",
    "        cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0aa00524-ce63-467f-9996-7e2c3d43c4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13215"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c478dd4e-55d1-4963-a8bc-3cfdc2950ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [[]]\n",
    "for i, sent in enumerate(test_word):\n",
    "    for j, word in enumerate(sent):\n",
    "        l[i].append(np.argmax(res[i][j]))\n",
    "    if i<len(test_word)-1:\n",
    "        l.append([])\n",
    "\n",
    "dev_labels = [[]]\n",
    "for i, sent in enumerate(test_word):\n",
    "    for j, word in enumerate(sent):\n",
    "        dev_labels[i].append(idx2tag[l[i][j]])\n",
    "    if i<len(test_word)-1:\n",
    "        dev_labels.append([])\n",
    "        \n",
    "with open('test_pred_labels_f.txt', 'w') as f:\n",
    "    for line in dev_labels:\n",
    "        for word in line:\n",
    "            f.write(f\"{word}\\n\")\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cedd28-8bb4-4770-bea5-849ab3bc955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
